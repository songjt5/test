hashMap扩容机制（由数组扩容到链表）
	1.7及之前，当前存放数据是发生了hash冲突，并且当前map的数量超过了阈值
	1.8存放新值后，已有元素数量大于等于阈值
	第一次添加元素的时候，默认初期长度为16，当往map中继续添加元素的时候，通过hash值跟数组长度取“与”来决定放在数组的哪个位置，如果出现放在同一个位置的时候，优先以链表的形式存放，
	在同一个位置的个数又达到了8个（代码是>=7,从0开始，及第8个开始判断是否转化成红黑树），如果数组的长度还小于64的时候，则会扩容数组。如果数组的长度大于等于64的话，
	才会将该节点的链表转换成树。在扩容完成之后，如果某个节点的是树，同时现在该节点的个数又小于等于6个了，则会将该树转为链表。
hashMap允许key和value为空，hashTable不允许
为什么hashMap是线程不安全的，currentHashMap是线程安全的？
	HashMap的底层存储结构，HashMap底层是一个Entry数组，一旦发生Hash冲突的的时候，HashMap采用拉链法解决碰撞冲突，就是扩容为链表
	导致hashMap线程不安全的场景：
HashMap的加载因子为什么是0.75？
	HashMap的初始容量是16，扩容方式为2N，加载因子为0.75。
	原因是提高空间利用率和减少查询成本的折中，主要是 泊松分布，0.75的话碰撞最小.
	初始容量是哈希表在被创建时的容量，加载因子是哈希表在自动扩容之前可以达到的最大的一种度量。
	当哈希表中的条目数超过了加载因子与当前容量的积时，需要对哈希表进行扩容、rehash操作（重组其内部结构），扩容后的哈希表将具有两倍的容量
	加载因子过低，例如0.5，可以减少查询时间成本，但是空间利用率很低，同时会提高rehash的次数
	选择0.75作为默认的加载因子，完全是时间和空间成本上寻求的一种折中选择
ConcurrentHashMap 在 put一个数据时的处理的具体流程
	1、计算要 put 的 key 的位置，获取指定位置的 Segmen
	2、如果指定位置的 Segment 为空，则初始化这个 Segment
	初始化segment的流程：
		1、检查计算得到的位置的 Segment 是否为null.
		2、为 null 继续初始化，使用 Segment[0] 的容量和负载因子创建一个 HashEntry 数组。
		3、再次检查计算得到的指定位置的 Segment 是否为null.
		4、使用创建的 HashEntry 数组初始化这个 Segment.
		5、自旋判断计算得到的指定位置的 Segment 是否为null，使用 CAS 在这个位置赋值为 Segment
	3、Segment.put 插入 key,value 值
	由于 Segment 继承了 ReentrantLock，所以 Segment 内部可以很方便的获取锁，put 流程就用到了这个功能
		1、tryLock() 获取锁，获取不到使用 scanAndLockForPut 方法继续获取。
		2、计算 put 的数据要放入的 index 位置，然后获取这个位置上的 HashEntry 
	jdk1.7segment数组 + HashEntry数组 + 链表	
	jdk1.8之后采用node数组 + 链表/红黑树		